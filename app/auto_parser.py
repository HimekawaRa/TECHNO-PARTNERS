import logging
import os
from PIL import Image
import pypandoc
from fastapi import FastAPI
from docx import Document
from docx.document import Document as _Document
from docx.oxml.text.paragraph import CT_P
from docx.oxml.table import CT_Tbl
from docx.table import Table as _Table
from docx.text.paragraph import Paragraph
import re
import subprocess
app = FastAPI()
logger = logging.getLogger(__name__)

def iter_block_items(parent):
    if isinstance(parent, _Document):
        body = parent.element.body
    else:
        raise ValueError("Unsupported parent")
    for child in body.iterchildren():
        if isinstance(child, CT_P):
            yield Paragraph(child, parent)
        elif isinstance(child, CT_Tbl):
            yield _Table(child, parent)

def split_docx_into_questions(input_path: str, output_dir: str) -> list[str]:
    os.makedirs(output_dir, exist_ok=True)
    doc = Document(input_path)
    header_re = re.compile(r'^\d+\.?\s*–∑–∞–¥–∞–Ω–∏', re.IGNORECASE)
    blocks = list(iter_block_items(doc))
    starts = [i for i, b in enumerate(blocks)
              if isinstance(b, Paragraph) and header_re.match(b.text.strip())]
    if not starts:
        raise ValueError("–ó–∞–≥–æ–ª–æ–≤–∫–∏ –∑–∞–¥–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    ranges = [
        (s, starts[idx+1]-1 if idx+1 < len(starts) else len(blocks)-1)
        for idx, s in enumerate(starts)
    ]
    out_paths = []
    for num, (s, e) in enumerate(ranges, start=1):
        part = Document(input_path)
        body = part.element.body
        elems = list(body)
        for i in range(len(elems)-1, -1, -1):
            if i < s or i > e:
                if elems[i].tag.endswith('}sectPr'):
                    continue
                body.remove(elems[i])
        out_file = os.path.join(output_dir, f"question{num}.docx")
        part.save(out_file)
        out_paths.append(out_file)
    return out_paths


def split_questions_logic(src: str) -> list[dict]:
    tmp = os.path.dirname(src)
    docname = os.path.splitext(os.path.basename(src))[0]
    docname = docname.replace(' ', '_')  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞

    # 1) –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
    parts_dir = os.path.join(tmp, "parts")
    part_paths = split_docx_into_questions(src, parts_dir)

    # 2) –ì–æ—Ç–æ–≤–∏–º –ø–∞–ø–∫—É –¥–ª—è –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤
    media_dir = os.path.join(tmp, "media")
    os.makedirs(media_dir, exist_ok=True)

    questions: list[dict] = []
    for idx, path in enumerate(part_paths, start=1):
        # 3) –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ Markdown —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –º–µ–¥–∏–∞
        md = pypandoc.convert_file(
            path,
            to="markdown+tex_math_dollars",
            format="docx",
            extra_args=[
                "--wrap=none",
                f"--extract-media={media_dir}"
            ],
        ).strip()

        # 4) –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        for root, _, files in os.walk(media_dir):
            for name in files:
                try:
                    src_path = os.path.join(root, name)

                    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                    normalized_name = name.replace(' ', '_')
                    if normalized_name != name:
                        normalized_path = os.path.join(root, normalized_name)
                        os.rename(src_path, normalized_path)
                        src_path = normalized_path
                        name = normalized_name

                    base, ext = os.path.splitext(name)
                    dst_path = os.path.join(root, f"{base}.jpg")

                    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è WMF/EMF —á–µ—Ä–µ–∑ LibreOffice
                    if ext.lower() in ['.emf', '.wmf']:
                        subprocess.run([
                            "libreoffice",
                            "--headless",
                            "--convert-to", "png",
                            src_path,
                            "--outdir", root
                        ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                        os.remove(src_path)
                        src_path = os.path.join(root, f"{base}.png")

                    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ JPEG —á–µ—Ä–µ–∑ PIL
                    if not src_path.endswith('.jpg'):
                        img = Image.open(src_path)
                        rgb_img = img.convert('RGB')
                        final_name = f"{base.replace(' ', '_')}.jpg"
                        final_path = os.path.join(root, final_name)
                        rgb_img.save(final_path, 'JPEG')
                        if src_path != final_path:
                            os.remove(src_path)

                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {src_path}: {str(e)}")

        # 5) –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Å—ã–ª–æ–∫ –≤ Markdown
        md = normalize_image_links(md, docname)

        questions.append({
            "number": idx,
            "text": md,
        })

    return questions

LETTER_TO_INDEX = {"A": 0, "B": 1, "C": 2, "D": 3}


def transform_questions(items):
    results = []
    for item in items:
        raw_text = item.get('text', '')
        if not raw_text:
            continue  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π

        # 1. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: —É–±–∏—Ä–∞–µ–º \r, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ \n, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        text = raw_text.replace('\r', '')
        lines = [ln for ln in text.split('\n') if ln.strip() != '']

        # 2. –£–¥–∞–ª–µ–Ω–∏–µ –º–µ–¥–∏–∞-–≤—Å—Ç–∞–≤–æ–∫ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ —Ç.–ø.)
        filtered_lines = []
        for ln in lines:
            low = ln.lower()
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–≥–ª—è–¥—è—Ç –∫–∞–∫ –≤—Å—Ç–∞–≤–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/–º–µ–¥–∏–∞
            if low.startswith('![') or low.startswith('<img') or 'data:image' in low:
                continue
            if any(ext in low for ext in ('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
                # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ .png –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç http-—Å—Å—ã–ª–∫—É –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫—É)
                if 'http' in low or low.strip().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
                    continue
            filtered_lines.append(ln)
        lines = filtered_lines

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        qid = item.get('id')  # –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–¥–∞–Ω–∏—è
        result_item = {
            "id": qid,
            "id_predmet": 1,
            "subject": {"name": "–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞", "namekz": "–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞"},
            "vopros": "",
            "temy": "",
            "temyname": "",
            "temyid": "",
            "target": "",
            "tip": 1,
            "texty": "",
            "otvety": [],
            "pravOtv": [],
            "exp": ""
        }

        # 3. –ü–æ–∏—Å–∫ –Ω–∞—á–∞–ª–∞ –≤–æ–ø—Ä–æ—Å–∞ (—Å—Ç—Ä–æ–∫–∞ —Å "N –∑–∞–¥–∞–Ω–∏–µ") –∏ —Å–±–æ—Ä —Å—Ç—Ä–æ–∫ –≤–æ–ø—Ä–æ—Å–∞
        question_lines = []
        start_idx = 0
        for idx, ln in enumerate(lines):
            # –ò—â–µ–º —à–∞–±–ª–æ–Ω "—á–∏—Å–ª–æ. –∑–∞–¥–∞–Ω–∏–µ" –∏–ª–∏ "—á–∏—Å–ª–æ –∑–∞–¥–∞–Ω–∏–µ" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –ø–æ—Å–ª–µ '>' —Å–∏–º–≤–æ–ª–∞)
            match = re.match(r'^\s*(?:>\s*)?(\d+\.?\s*–∑–∞–¥–∞–Ω–∏–µ\.?)(.*)', ln, flags=re.IGNORECASE)
            if match:
                # –†–∞–∑–¥–µ–ª—è–µ–º —Å—Ç—Ä–æ–∫—É –Ω–∞ —á–∞—Å—Ç—å –ø–æ—Å–ª–µ "–∑–∞–¥–∞–Ω–∏–µ"
                trailing_text = match.group(2)
                if trailing_text:
                    # –ï—Å–ª–∏ –Ω–∞ —Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–µ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞ –ø–æ—Å–ª–µ "–∑–∞–¥–∞–Ω–∏–µ", –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
                    question_lines.append(trailing_text.strip())
                # –û—Ç–º–µ—Ç–∏–º, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
                start_idx = idx + 1
                break

        # –°–æ–±–∏—Ä–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å—Ç—Ä–æ–∫–∏ –≤–æ–ø—Ä–æ—Å–∞ –¥–æ –Ω–∞—á–∞–ª–∞ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤ –∏–ª–∏ —Å–ª—É–∂–µ–±–Ω–æ–π —Å–µ–∫—Ü–∏–∏
        for idx in range(start_idx, len(lines)):
            ln = lines[idx]
            # –ü—Ä–µ—Ä—ã–≤–∞–µ–º, –µ—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –Ω–∞—á–∞–ª–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏–ª–∏ –¥—Ä—É–≥—É—é —Å–µ–∫—Ü–∏—é
            if re.match(r'^\s*[A-F]\)', ln) or ln.startswith(
                    ("–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç", "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:", "–†–∞–∑–¥–µ–ª:", "–¢–µ–º–∞:", "–¶–µ–ª—å:", "–ë–∞–ª–ª:", "–£—á–µ–±–Ω–∏–∫:")):
                break
            question_lines.append(ln)

        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å—Ç—Ä–æ–∫ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∞ LaTeX
        def combine_preserving_latex(line_list):
            combined = ""
            in_latex_block = False
            for i, ln in enumerate(line_list):
                stripped = ln.strip()
                # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–∞–º–∞ –ø–æ —Å–µ–±–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ $$ (–æ–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞)
                if stripped.startswith("$$") and stripped.endswith("$$"):
                    combined += stripped
                    if i != len(line_list) - 1:
                        combined += " "
                    continue
                # –ï—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è $$ (–º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞)
                if stripped.startswith("$$") and not stripped.endswith("$$"):
                    in_latex_block = True
                    combined += stripped + "\n"
                    continue
                # –ï—Å–ª–∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è $$ (–∫–æ–Ω–µ—Ü –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω–æ–π —Ñ–æ—Ä–º—É–ª—ã)
                if stripped.endswith("$$") and in_latex_block:
                    combined += stripped
                    in_latex_block = False
                    if i != len(line_list) - 1:
                        combined += " "
                    continue
                # –ï—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –æ–∫—Ä—É–∂–µ–Ω–∏–µ \begin{...}
                if stripped.startswith("\\begin{"):
                    in_latex_block = True
                    combined += ln + "\n"
                    continue
                # –ï—Å–ª–∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –æ–∫—Ä—É–∂–µ–Ω–∏–µ \end{...}
                if in_latex_block and stripped.startswith("\\end{"):
                    combined += ln
                    in_latex_block = False
                    if i != len(line_list) - 1:
                        combined += " "
                    continue
                # –ï—Å–ª–∏ –≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∞ LaTeX, –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º
                if in_latex_block:
                    combined += ln + "\n"
                    continue
                # –û–±—ã—á–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–Ω–µ LaTeX-–±–ª–æ–∫–∞: –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —Å –ø—Ä–æ–±–µ–ª–æ–º
                combined += stripped
                if i != len(line_list) - 1:
                    combined += " "
            return combined.strip()

        # –ü–æ–ª—É—á–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞
        result_item["vopros"] = combine_preserving_latex(question_lines)

        # 4. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤
        answers_lines = []
        # –ù–∞–π–¥—ë–º –∏–Ω–¥–µ–∫—Å –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏, –ø–æ—Ö–æ–∂–µ–π –Ω–∞ "A) ...", —á—Ç–æ–±—ã –∑–Ω–∞—Ç—å –æ—Ç–∫—É–¥–∞ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è –≤–∞—Ä–∏–∞–Ω—Ç—ã
        answer_start = None
        for idx, ln in enumerate(lines):
            if re.match(r'^\s*[A-F]\)', ln):
                answer_start = idx
                break
        # –°–æ–±–µ—Ä—ë–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞, –ø–æ–∫–∞ –Ω–µ –≤—Å—Ç—Ä–µ—Ç–∏–º —Å–ª—É–∂–µ–±–Ω—É—é –º–µ—Ç–∫—É
        if answer_start is not None:
            for idx in range(answer_start, len(lines)):
                ln = lines[idx]
                if ln.startswith(("–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç", "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:", "–†–∞–∑–¥–µ–ª:", "–¢–µ–º–∞:", "–¶–µ–ª—å:", "–ë–∞–ª–ª:", "–£—á–µ–±–Ω–∏–∫:")):
                    break
                answers_lines.append(ln)

        # –†–∞–∑–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ answers_lines –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        structured_answers = []
        current_option = None
        current_text = ""
        for ln in answers_lines:
            option_match = re.match(r'^\s*([A-F])\)\s*(.*)', ln)
            if option_match:
                # –ù–∞—á–∞–ª–æ –Ω–æ–≤–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ (–±—É–∫–≤–∞ –∏ —Ç–µ–∫—Å—Ç)
                if current_option is not None:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –Ω–æ–≤–æ–≥–æ
                    structured_answers.append((current_option, current_text.strip()))
                current_option = option_match.group(1)  # –±—É–∫–≤–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ (A, B, ...)
                current_text = option_match.group(2)  # —Ç–µ–∫—Å—Ç –≤–∞—Ä–∏–∞–Ω—Ç–∞ (–ø–æ—Å–ª–µ "A)")
            else:
                # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Ç–µ–∫—É—â–µ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ (–µ—Å–ª–∏ –≤–∞—Ä–∏–∞–Ω—Ç –∑–∞–Ω–∏–º–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫)
                if current_option is not None:
                    current_text += " " + ln.strip()
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞—Ä–∏–∞–Ω—Ç, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if current_option is not None:
            structured_answers.append((current_option, current_text.strip()))

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ –±—É–∫–≤–µ (–Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –≤—ã—à–ª–∏ –∏–∑ –ø–æ—Ä—è–¥–∫–∞)
        structured_answers.sort(key=lambda x: x[0])
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –≤ —Å–ø–∏—Å–æ–∫
        answers_texts = [text for _, text in structured_answers]
        # –ï—Å–ª–∏ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –º–µ–Ω—å—à–µ 4, –¥–æ–ø–æ–ª–Ω—è–µ–º –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
        while len(answers_texts) < 4:
            answers_texts.append("")
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 6 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –º–∞–∫—Å–∏–º—É–º (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –±–æ–ª—å—à–µ, —Ö–æ—Ç—è –Ω–µ –æ–∂–∏–¥–∞–µ—Ç—Å—è –±–æ–ª–µ–µ 6)
        if len(answers_texts) > 6:
            answers_texts = answers_texts[:6]
        result_item["otvety"] = answers_texts

        # 5. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (—Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤)
        for ln in lines:
            if ln.startswith("–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç"):
                # –ë–µ—Ä—ë–º —á–∞—Å—Ç—å –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è
                parts = ln.split(":", 1)
                letters_part = parts[1] if len(parts) > 1 else ""
                # –ò—â–µ–º –≤—Å–µ –±—É–∫–≤—ã A-F (–ª–∞—Ç–∏–Ω—Å–∫–∏–µ) –≤ —ç—Ç–æ–π —á–∞—Å—Ç–∏, –±–µ–∑ —É—á—ë—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞
                letters = re.findall(r'[A-F]', letters_part, flags=re.IGNORECASE)
                result_item["pravOtv"] = [ord(letter.upper()) - ord('A') for letter in letters]
                break

        # 6. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è (exp)
        exp_lines = []
        for idx, ln in enumerate(lines):
            if ln.startswith("–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:"):
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:" –Ω–∞ —Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–µ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç, –≤–∫–ª—é—á–∞–µ–º –µ–≥–æ
                content_after_colon = ln.split("–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:", 1)[1].strip()
                if content_after_colon:
                    exp_lines.append(content_after_colon)
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ—è—Å–Ω–µ–Ω–∏—è
                j = idx + 1
                while j < len(lines):
                    nxt = lines[j]
                    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è, –∫–æ–≥–¥–∞ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ —Å–ª–µ–¥—É—é—â—É—é —Å–ª—É–∂–µ–±–Ω—É—é —Å–µ–∫—Ü–∏—é
                    if nxt.startswith(("–£—á–µ–±–Ω–∏–∫:", "–†–∞–∑–¥–µ–ª:", "–¢–µ–º–∞:", "–¶–µ–ª—å:", "–ë–∞–ª–ª:")):
                        break
                    exp_lines.append(nxt)
                    j += 1
                break
        result_item["exp"] = combine_preserving_latex(exp_lines) if exp_lines else ""

        # 7. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞ (temy)
        for ln in lines:
            if ln.startswith("–†–∞–∑–¥–µ–ª:"):
                result_item["temy"] = ln.split("–†–∞–∑–¥–µ–ª:", 1)[1].strip()
                break

        # 8. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º—ã (temyname –∏ temyid)
        for ln in lines:
            if ln.startswith("–¢–µ–º–∞:"):
                tema_content = ln.split("–¢–µ–º–∞:", 1)[1].strip()
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —à–∞–±–ª–æ–Ω "—á–∏—Å–ª–æ-..." –∏–ª–∏ "—á–∏—Å–ª–æ ...", —á—Ç–æ–±—ã –≤—ã–¥–µ–ª–∏—Ç—å ID
                m = re.match(r'^(\d+)[\-\u2013\s]+(.*)', tema_content)
                if m:
                    result_item["temyid"] = m.group(1).strip()
                    result_item["temyname"] = m.group(2).strip()
                else:
                    # –ï—Å–ª–∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ —É–∫–∞–∑–∞–Ω, –≤—Å—è —Å—Ç—Ä–æ–∫–∞ - –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã
                    result_item["temyid"] = ""
                    result_item["temyname"] = tema_content
                break

        # 9. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–ª–∏ (target)
        for idx, ln in enumerate(lines):
            if ln.startswith("–¶–µ–ª—å:"):
                # –ë–µ—Ä—ë–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ "–¶–µ–ª—å:"
                target_content = ln.split("–¶–µ–ª—å:", 1)[1].strip()
                target_lines = [target_content] if target_content else []
                # –°–æ–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏ –¥–æ —Å–ª–µ–¥—É—é—â–µ–π —Å–ª—É–∂–µ–±–Ω–æ–π –º–µ—Ç–∫–∏
                j = idx + 1
                while j < len(lines):
                    nxt = lines[j]
                    if nxt.startswith(("–ë–∞–ª–ª:", "–£—á–µ–±–Ω–∏–∫:", "–†–∞–∑–¥–µ–ª:", "–¢–µ–º–∞:")):
                        break
                    target_lines.append(nxt)
                    j += 1
                result_item["target"] = combine_preserving_latex(target_lines) if target_lines else ""
                break

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –∑–∞–¥–∞–Ω–∏—è –≤ —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–π —Å–ø–∏—Å–æ–∫
        results.append(result_item)
    return results




def wrap_raw(raw_item) -> dict:
    """
    raw_item –º–æ–∂–µ—Ç –±—ã—Ç—å –ª–∏–±–æ —Å—Ç—Ä–æ–∫–æ–π, –ª–∏–±–æ dict —Å –∫–ª—é—á–æ–º 'text'.
    –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ —Å–∞–º –æ–±—ä–µ–∫—Ç, –∏ —á–∏—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –≤ state.
    """
    if isinstance(raw_item, dict) and "text" in raw_item:
        text = raw_item["text"]
    elif isinstance(raw_item, str):
        text = raw_item
    else:
        # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ
        text = str(raw_item)
    return {"raw": raw_item, "text": text}


def extract_number_and_vopros(state: dict) -> dict:
    text = state["text"]
    logger.debug("STEP1: raw text:\n%s", text)

    lines = [l.strip() for l in text.replace("\r", "").split("\n")]
    logger.debug("STEP1: total %d lines", len(lines))

    num = None
    vopros = "–≤–æ–ø—Ä–æ—Å –Ω–µ –æ–ø–æ–∑–Ω–∞–Ω"

    pattern = re.compile(
        r'^\s*(?:>\s*)?(\d+)(?:\\\.)?\.?\s*–∑–∞–¥–∞–Ω–∏–µ\.?', flags=re.IGNORECASE
    )

    for i, ln in enumerate(lines):
        m = pattern.match(ln) or re.match(r'^\s*(?:>\s*)?(\d+)\s*–∑–∞–¥–∞–Ω–∏–µ', ln, flags=re.IGNORECASE)
        if m:
            num = int(m.group(1))
            tail = ln[m.end():].strip()
            logger.debug("STEP1: matched number=%r, raw tail=%r", num, tail)

            if tail:
                vopros = tail
                logger.debug("STEP1: vopros taken from same line: %r", vopros)
            else:
                # üîΩ –°–æ–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–æ –ø–µ—Ä–≤–æ–π –æ–ø—Ü–∏–∏ A)‚ÄìF)
                vopros_lines = []
                for j in range(i + 1, len(lines)):
                    if re.match(r'^[A-F–ê-–Ø]\\?\)', lines[j]):  # –Ω–∞—á–∞–ª–æ –±–ª–æ–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤
                        break
                    if lines[j]:
                        vopros_lines.append(lines[j])
                if vopros_lines:
                    vopros = " ".join(vopros_lines).strip()
                    logger.debug("STEP1: vopros assembled from lines: %r", vopros)
            break

    if num is None:
        logger.warning("STEP1: –Ω–æ–º–µ—Ä –∑–∞–¥–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω, –æ—Å—Ç–∞–≤–ª—è–µ–º None")
    else:
        logger.info("STEP1: –∏–∑–≤–ª–µ—á—ë–Ω –Ω–æ–º–µ—Ä=%s, –≤–æ–ø—Ä–æ—Å=%r", num, vopros)

    new = state.copy()
    new.update({"number": num, "vopros": vopros})
    return new

# –®–∞–≥ 2: temy, temyid, temyname
def extract_temy(state: dict) -> dict:
    temy_id = temy_name = podtemy_id = podtemy_name = None

    for ln in state.get("text", "").splitlines():
        # 1) –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º ¬´–†–∞–∑–¥–µ–ª:¬ª
        if ln.startswith("–†–∞–∑–¥–µ–ª:"):
            raw = ln.split("–†–∞–∑–¥–µ–ª:", 1)[1].strip()
            # –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –Ω–æ–º–µ—Ä –∏ –∏–º—è —Å–µ–∫—Ü–∏–∏
            m0 = re.match(r'^(\d+)[\-\u2013\s]*(.+)$', raw)
            if m0:
                temy_id   = m0.group(1)
                temy_name = m0.group(2).strip().rstrip('.')
            else:
                temy_name = raw.rstrip('.')

        # 2) –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º ¬´–¢–µ–º–∞:¬ª –∏ –∑–∞—Ç–µ–º –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
        elif ln.startswith("–¢–µ–º–∞:"):
            raw = ln.split("–¢–µ–º–∞:", 1)[1].strip()
            m1 = re.match(r'^(\d+)[\-\u2013\s]+(.+)', raw)
            if m1:
                podtemy_id   = m1.group(1)
                podtemy_name = m1.group(2).strip().rstrip('.')
            else:
                podtemy_name = raw.rstrip('.')
            break

    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    new_state = state.copy()
    new_state.update({
        "temy_id":      temy_id,
        "temy_name":    temy_name,
        "podtemy_id":   podtemy_id,
        "podtemy_name": podtemy_name,
    })
    return new_state

# –®–∞–≥ 3: otvety
def extract_otvety(state: dict) -> dict:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–æ–≤–Ω–æ 4 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤ A)‚ÄìD) –∏–∑ state["text"].
    –£–±–∏—Ä–∞–µ—Ç –≤–µ–¥—É—â–∏–µ '>' –∏ –ø—Ä–æ–±–µ–ª—ã, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã,
    –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –≤—Å—Ç—Ä–µ—á–µ '–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç', '–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:' –∏ —Ç.–ø.
    """
    import re
    text = state["text"]
    raw_lines = text.split("\n")

    # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã ‚Üí –ª–∞—Ç–∏–Ω–∏—Ü–∞ (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –±—É–∫–≤—ã –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤)
    translit = {"–ê": "A", "–í": "B", "–°": "C", "D": "D", "E": "E", "F": "F"}
    lines = [ln.translate(str.maketrans(translit)).lstrip("> ").rstrip() for ln in raw_lines]

    # 2) –ù–∞–π–¥—ë–º –Ω–∞—á–∞–ª–æ –±–ª–æ–∫–∞ ‚Äî –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ "X)" –∏–ª–∏ "X\)"
    start_idx = None
    start_re = re.compile(r'^\s*[A-F]\\?\)\s*')  # —Ç–µ–ø–µ—Ä—å —Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã
    for i, ln in enumerate(lines):
        if start_re.match(ln):
            start_idx = i
            logger.debug("STEP3: options start at line %d: %r", i, ln)
            break

    opts = []
    if start_idx is not None:
        # 3) –°–æ–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–æ –ø–µ—Ä–≤–æ–π ¬´—Å–ª—É–∂–µ–±–Ω–æ–π¬ª –º–µ—Ç–∫–∏
        block = []
        for ln in lines[start_idx:]:
            if re.match(r'^(–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç|–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:|–†–∞–∑–¥–µ–ª:|–¢–µ–º–∞:|–¶–µ–ª—å:|–ë–∞–ª–ª:)', ln):
                logger.debug("STEP3: hit end-of-options at %r", ln)
                break
            block.append(ln)

        # 4) –ü–∞—Ä—Å–∏–º –≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∞: –Ω–æ–≤–∞—è –æ–ø—Ü–∏—è –ø—Ä–∏ –≤—Å—Ç—Ä–µ—á–µ "X)" –∏–ª–∏ "X\)"
        curr = None
        opt_re = re.compile(r'^\s*([A-F])\\?\)\s*(.*)')
        for ln in block:
            m = opt_re.match(ln)
            if m:
                if curr is not None:
                    opts.append(curr.strip())
                curr = m.group(2).strip()
                logger.debug("STEP3: new option %r: %r", m.group(1), curr)
            else:
                if curr is not None:
                    curr += " " + ln.strip()
        if curr is not None:
            opts.append(curr.strip())

    logger.info("STEP3: final otvety = %r", opts)
    new = state.copy()
    new["otvety"] = opts
    return new
#
# def extract_prav_otv(state: dict) -> dict:
#     """
#     –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞, –≤–∫–ª—é—á–∞—è A|, B|, ..., –¥–∞–∂–µ –µ—Å–ª–∏ —Ç–∞–∫–∏—Ö –Ω–µ—Å–∫–æ–ª—å–∫–æ.
#     """
#     text = state.get("text", "")
#     text_cleaned = text.replace("\r", "").replace("\n", " ")  # –Ω–∞ —Å–ª—É—á–∞–π –ø–µ—Ä–µ–Ω–æ—Å–∞
#
#     # –ò—â–µ–º –≤—Å–µ –±—É–∫–≤—ã A‚ÄìF –ø–µ—Ä–µ–¥ \|, –∫–∞–∫ –≤ "A\|", "B\|"
#     found = re.findall(r'([A-F])\\\|', text_cleaned, flags=re.IGNORECASE)
#     logger.debug("STEP4: found letters = %r", found)
#
#     # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∏–Ω–¥–µ–∫—Å—ã
#     mapping = {"A": 0, "B": 1, "C": 2, "D": 3, "E": 4, "F": 5}
#     indexes = [mapping[letter.upper()] for letter in found if letter.upper() in mapping]
#
#     logger.info("STEP4: pravOtv indexes = %r", indexes)
#
#     new = state.copy()
#     new["pravOtv"] = indexes
#     return new

def extract_prav_otv(state: dict) -> dict:
    import re

    text = state.get("text", "")
    text_cleaned = text.replace("\r", "").replace("\n", " ")

    # –ö–∏—Ä–∏–ª–ª–∏—Ü–∞ ‚Üí –ª–∞—Ç–∏–Ω–∏—Ü–∞
    translit = {
        '–ê': 'A', '–í': 'B', '–°': 'C', '–î': 'D', '–ï': 'E', '–§': 'F',
        '–∞': 'A', '–≤': 'B', '—Å': 'C', '–¥': 'D', '–µ': 'E', '—Ñ': 'F'
    }
    for k, v in translit.items():
        text_cleaned = text_cleaned.replace(k, v)

    # –ù–∞–π—Ç–∏ –≤—Å–µ –±—É–∫–≤—ã A‚ÄìF –ø–µ—Ä–µ–¥ | –∏–ª–∏ –≤–Ω—É—Ç—Ä–∏ "–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç:"
    # –ü—Ä–∏–º–µ—Ä—ã: A|, A |, A]|, A:[ , –∏ —Ç.–ø.
    found = re.findall(r'–ü—Ä–∞–≤–∏–ª—å–Ω(?:—ã–π|—ã–µ)\s+–æ—Ç–≤–µ—Ç[–∞-—è:\s]*([A-F](?:[,|; ]+[A-F])*)', text_cleaned, flags=re.IGNORECASE)

    letters = []
    if found:
        # –ü—Ä–∏–º–µ—Ä: "A, B", "A;B", "A|B"
        raw_ans = found[0]
        letters = re.findall(r'[A-F]', raw_ans)

    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–±, –µ—Å–ª–∏ —à–∞–±–ª–æ–Ω –≤—ã—à–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª:
    if not letters:
        letters = re.findall(r'\b([A-F])\s*\\?\|', text_cleaned)

    mapping = {"A": 0, "B": 1, "C": 2, "D": 3, "E": 4, "F": 5}
    indexes = [mapping[l] for l in letters if l in mapping]

    new = state.copy()
    new["pravOtv"] = indexes
    return new

# –®–∞–≥ 5: exp

def extract_exp(state: dict) -> dict:
    exp_lines = []
    lines = state["text"].split("\n")

    for i, ln in enumerate(lines):
        if ln.startswith("–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:"):
            tail = ln.split("–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:", 1)[1].strip()
            if tail:
                exp_lines.append(tail)
            for nxt in lines[i + 1:]:
                if re.match(r'^(–†–∞–∑–¥–µ–ª:|–¢–µ–º–∞:|–¶–µ–ª—å:|–ë–∞–ª–ª:|–£—á–µ–±–Ω–∏–∫:)', nxt):
                    break
                exp_lines.append(nxt.strip())
            break

    explanation = " ".join(exp_lines).strip()

    new = state.copy()
    new["exp"] = explanation
    return new

# –®–∞–≥ 6: target
def extract_target(state: dict) -> dict:
    target_lines = []
    lines = state["text"].split("\n")
    for i, ln in enumerate(lines):
        if ln.startswith("–¶–µ–ª—å:"):
            tail = ln.split("–¶–µ–ª—å:",1)[1].strip()
            if tail:
                target_lines.append(tail)
            for nxt in lines[i+1:]:
                if re.match(r'^(–ë–∞–ª–ª:|–£—á–µ–±–Ω–∏–∫:|–†–∞–∑–¥–µ–ª:|–¢–µ–º–∞:)', nxt):
                    break
                target_lines.append(nxt.strip())
            break

    # –°–±–æ—Ä –∏–∑ —Å—Ç—Ä–æ–∫
    target = " ".join(target_lines).strip()

    # –£–±–∏—Ä–∞–µ–º –í–°–ï —Å–∏–º–≤–æ–ª—ã '>' –∏ leading —Ç–æ—á–∫—É/–ø—Ä–æ–±–µ–ª—ã
    target = re.sub(r'^[\.\s>]+', '', target)  # —É–¥–∞–ª—è–µ–º –≤ –Ω–∞—á–∞–ª–µ ., >, –ø—Ä–æ–±–µ–ª—ã
    target = target.replace('>', '')           # —É–¥–∞–ª—è–µ–º –≤—Å–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è '>'
    target = re.sub(r'\s{2,}', ' ', target)    # —Å–≤–æ–¥–∏–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∫ –æ–¥–Ω–æ–º—É
    target = target.strip()

    new = state.copy()
    new["target"] = target
    return new

# –°–æ–±–∏—Ä–∞—é—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def pipeline_mcq(raw_item) -> dict:
    st = wrap_raw(raw_item)
    st = extract_number_and_vopros(st)
    st = extract_temy(st)
    st = extract_otvety(st)
    st = extract_prav_otv(st)
    st = extract_exp(st)
    st = extract_target(st)
    return st



def extract_matching_number_and_vopros(state: dict) -> dict:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä –∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –≤–æ–ø—Ä–æ—Å–∞ (–æ–±—Ä–µ–∑–∞–µ—Ç –ø–æ –ª–∏–Ω–∏–∏ '----').
    """
    text = state["text"]
    logger.debug("MATCHING STEP1: raw text:\n%s", text)

    lines = [l.strip() for l in text.replace("\r", "").split("\n")]
    num = None
    vopros = "–≤–æ–ø—Ä–æ—Å –Ω–µ –æ–ø–æ–∑–Ω–∞–Ω"

    # –ü–æ–∏—Å–∫ —Å—Ç—Ä–æ–∫–∏ —Å –Ω–æ–º–µ—Ä–æ–º –∑–∞–¥–∞–Ω–∏—è
    zadanie_re = re.compile(r"^\s*(\d+)\s*(?:–∑–∞–¥–∞–Ω–∏[–µ—è]?)", re.IGNORECASE)
    start_line_idx = None

    for i, line in enumerate(lines):
        m = zadanie_re.match(line)
        if m:
            num = int(m.group(1))
            start_line_idx = i
            break

    if start_line_idx is not None:
        vopros_lines = []
        for line in lines[start_line_idx + 1:]:
            if re.search(r"-{5,}", line):  # –æ–±—Ä–µ–∑–∞–µ–º –ø–æ –ª–∏–Ω–∏–∏
                break
            if line:
                vopros_lines.append(line)
        vopros = " ".join(vopros_lines).strip(" .:")
        logger.debug("MATCHING STEP1: vopros assembled: %r", vopros)
    else:
        logger.warning("MATCHING STEP1: –Ω–æ–º–µ—Ä –∑–∞–¥–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω")

    return state | {"number": num, "vopros": vopros}


def extract_matching_options(state: dict) -> dict:
    raw = state.get("text", "")
    # 1) –°–Ω–∏–º–∞–µ–º —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ—á–µ–∫, —Å–∫–æ–±–æ–∫ –∏ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–æ–∫
    text = (raw
            .replace(r"\.", ".")
            .replace(r"\)", ")")
            .replace(r"\[", "[")
            .replace(r"\]", "]"))

    lines = text.splitlines()
    group1 = {}
    group2 = {}
    in_block = False

    for i, ln in enumerate(lines):
        # 2) –ò—â–µ–º –Ω–∞—á–∞–ª–æ –±–ª–æ–∫–∞ ("1. ")
        if not in_block:
            if re.match(r"^\s*1[.)]\s+", ln):
                in_block = True
            else:
                continue

        # 3) –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
        if re.match(r"^\s*(–†–∞–∑–¥–µ–ª:|–¢–µ–º–∞:|–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:|–ë–∞–ª–ª:|–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç:)", ln):
            break

        # 4) –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —á–∏—Å—Ç–æ –¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏
        if re.match(r"^\s*-{3,}\s*$", ln):
            continue

        # 5) –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ "N. <—Ç–µ–∫—Å—Ç>  X) <–≤–∞—Ä–∏–∞–Ω—Ç>"
        m = re.match(r"^\s*(\d+)[\.\)]\s+(.+)$", ln)
        if not m:
            continue

        idx = int(m.group(1)) - 1
        rest = m.group(2).strip()

        # 6) –î–µ–ª–∏–º –ø–æ –ø–µ—Ä–≤–æ–º—É –≤—Ö–æ–∂–¥–µ–Ω–∏—é "A)"/"B)"/‚Ä¶/"E)"
        parts = re.split(r"\s+([A-E])\)\s+", rest, maxsplit=1)
        if len(parts) == 3:
            left, letter, right = parts
            group1[idx] = left.strip()
            group2[idx] = right.strip()
        else:
            group1[idx] = rest


    # 7) –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π state —Å –Ω–æ–≤—ã–º–∏ otvety
    new_state = state.copy()
    new_state["otvety"] = {"group1": group1, "group2": group2}
    return new_state

def extract_matching_pravotv(st: dict) -> dict:
    """
    –ò—â–µ—Ç –≤ raw.text —Å—Ç—Ä–æ–∫—É '–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç:' –∏ –ø–∞—Ä—Å–∏—Ç –ø–∞—Ä—ã –≤–∏–¥–∞ '1-C', '2-A' –∏ —Ç.–¥.
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ st['pravOtv'] –≤ –≤–∏–¥–µ —Å–ª–æ–≤–∞—Ä—è {left_idx: ['ts-right_idx'], ...}.
    """
    text = st.get("raw", {}).get("text", "")
    m = re.search(r"–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç[:Ôºö]\s*(.+)", text)
    if not m:
        st["pravOtv"] = {}
        return st

    parts = re.split(r"[Ôºå,]\s*", m.group(1))
    # —Å–∫–æ–ª—å–∫–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ group1
    group1 = st.get("otvety", {}).get("group1", {})
    n = len(group1)

    prav = {}
    for part in parts:
        m2 = re.match(r"\s*(\d+)\s*[-:]\s*([A-Z])", part)
        if not m2:
            continue
        left_idx = int(m2.group(1)) - 1           # –∏–∑ "1-C" –¥–µ–ª–∞–µ–º 0
        letter = m2.group(2)
        right_idx = ord(letter) - ord("A")        # –∏–∑ "C" –¥–µ–ª–∞–µ–º 2
        if 0 <= left_idx < n:
            prav[str(left_idx)] = [f"ts-{right_idx}"]

    st["pravOtv"] = prav
    return st

def pipeline_matching(raw_item) -> dict:
    st = wrap_raw(raw_item)
    st = extract_matching_number_and_vopros(st)
    st = extract_temy(st)
    st = extract_matching_options(st)
    st = extract_matching_pravotv(st)
    st = extract_exp(st)
    st = extract_target(st)
    return st






def build_rows_with_placeholders(
    states: list[dict],
    subject: dict,
    language: str,
    klass: str,
    tip: int) -> list[dict]:
    """
    –ò–∑ —Å–ø–∏—Å–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π (pipeline output) —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å –∑–∞–≥–ª—É—à–∫–∞–º–∏
    –¥–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤.
    """
    rows = []
    last_id = 0
    for state in states:
        curr_id = state.get("number")

        if curr_id is not None:
            # 1) –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
            for missing in range(last_id + 1, curr_id):
                logger.debug("Placeholder for missing question %d", missing)
                rows.append({
                    "id": missing,
                    "id_predmet": 1,
                    "subject": subject,
                    "language": language,
                    "klass": klass,
                    "vopros": "–≤–æ–ø—Ä–æ—Å –Ω–µ –æ–ø–æ–∑–Ω–∞–Ω",

                    "temy_id": None,
                    "temy_name": None,
                    "podtemy_id": None,
                    "podtemy_name": None,

                    "target": "",
                    "tip": tip,
                    "texty": "",
                    "otvety": ["", "", "", ""],
                    "pravOtv": [],
                    "exp": "",
                    "raw": None
                })

            # 2) –°–æ–±—Å—Ç–≤–µ–Ω–Ω–æ –≤–æ–ø—Ä–æ—Å
            rows.append({
                "id": curr_id,
                "id_predmet": 1,
                "subject": subject,
                "language": language,
                "klass": klass,
                "vopros": state.get("vopros", "–≤–æ–ø—Ä–æ—Å –Ω–µ –æ–ø–æ–∑–Ω–∞–Ω"),


                "temy_id": state.get("temy_id"),
                "temy_name": state.get("temy_name"),
                "podtemy_id": state.get("podtemy_id"),
                "podtemy_name": state.get("podtemy_name"),


                "target": state.get("target", ""),
                "tip": tip,
                "texty": "",
                "otvety": state.get("otvety", ["", "", "", ""]),
                "pravOtv": state.get("pravOtv", []),
                "exp": state.get("exp", ""),
                "raw": state.get("raw", None)
            })

            last_id = curr_id

        else:
            # –ï—Å–ª–∏ –Ω–æ–º–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º, —á—Ç–æ –µ—Å—Ç—å
            logger.debug("Unnumbered question, adding as-is")
            rows.append({
                "id": None,
                "id_predmet": 1,
                "subject": subject,
                "language": language,
                "klass": klass,
                "vopros": state.get("vopros", "–≤–æ–ø—Ä–æ—Å –Ω–µ –æ–ø–æ–∑–Ω–∞–Ω"),

                "temy_id": state.get("temy_id"),
                "temy_name": state.get("temy_name"),
                "podtemy_id": state.get("podtemy_id"),
                "podtemy_name": state.get("podtemy_name"),

                "target": state.get("target", ""),
                "tip": tip,
                "texty": "",
                "otvety": state.get("otvety", ["", "", "", ""]),
                "pravOtv": state.get("pravOtv", []),
                "exp": state.get("exp", ""),
                "raw": state.get("raw", None)
            })

    return rows


def clean_math_and_sub(s: str) -> str:
    if not s:
        return s

    # 0) –£–±–∏—Ä–∞–µ–º —ç–∫—Ä–∞–Ω–∏—Ä—É—é—â–∏–µ —Å–ª—ç—à–∏
    s = s.replace('\\', '')

    # 1) –î–≤–æ–π–Ω—ã–µ –¥–µ—Ñ–∏—Å—ã ‚Üí –æ–¥–∏–Ω–æ—á–Ω—ã–π
    s = s.replace('--', '-')

    # 2) –°–∫–æ–±–∫–∏ LaTeX-–∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ \[ ‚Ä¶ \] ‚Üí [ ‚Ä¶ ]
    s = s.replace('\[', '[').replace('\]', ']')

    # 3) x^n^ ‚Üí x^n
    s = re.sub(r'\^(\d+)\^', r'^\1', s)

    # 4) <sub>‚Ä¶</sub> –æ—Å—Ç–∞–≤–ª—è–µ–º (–∏–ª–∏ —É–∂–µ –µ—Å—Ç—å –≤ exp) ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º

    # 5) –¢–∏–ª—å–¥—ã ~‚Ä¶~ ‚Üí <sub>‚Ä¶</sub>
    s = re.sub(r'~([^~]+?)~', r'<sub>\1</sub>', s)

    # 6) –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–µ—Ä–µ–¥/–ø–æ—Å–ª–µ —Å–∫–æ–±–æ–∫
    s = re.sub(r'\s+\(', ' (', s)
    s = re.sub(r'\)\s+', ') ', s)

    return s.strip()


def normalize_image_links(md: str, docname: str) -> str:
    """
    –ò—â–µ—Ç –≤ Markdown –≤—Å–µ ![](path/to/–∏–º—è_—Ñ–∞–π–ª–∞)
    –∏ –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –∏—Ö –≤ ![](/img/<docname>/–∏–º—è_—Ñ–∞–π–ª–∞.jpg), –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    """
    docname = docname.replace(' ', '_')  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    def replacer(match):
        filename = match.group(1)
        filename = filename.replace(' ', '_')
        base, _ = os.path.splitext(filename)
        return f"![](/img/{docname}/{base}.jpg)"

    return re.sub(
        r'!\[\]\((?:.*?)[\\/]+([^\\/]+)\)',
        replacer,
        md
    )

